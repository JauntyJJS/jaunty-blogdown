---
title: "Learning Journey and Reflections on useR! 2022 Conference Part 2"
subtitle: ""
excerpt: "This narrative is a write up on my learning journey in the useR! 2022 Conference."
date: 2022-07-01
author: "Jeremy Selva"
draft: true
images:
series:
tags:
categories:
layout: single-sidebar
editor_options: 
  chunk_output_type: console
bibliography: utils/bibliography.bib
csl: utils/f1000research.csl
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(fig.align = "center")

```

## Introduction

In this narrative, I will share my learning journey during Day 3 and Day 4 of useR! 2022 Virtual Conference.

## Day 3

### First Keynote: afrimapr

The first keynote is by the [afrimapr](https://afrimapr.github.io/afrimapr.website/) project team. The project aims is to use R as a building block for many things such as better management of data realted to Africa, creation of open source analytical tools to analyse and provide insights across Africa, providing teaching resources and training for those interested in this novel work and building a strong community with this common interest.

[Anelda van der Walt](https://twitter.com/aneldavdw) shared the progress the team have made since it was first launched in 2020 such as [R packages](https://afrimapr.github.io/afrimapr.website/code/), [interactive apps](https://afrimapr.github.io/afrimapr.website/interactive-apps/), [teaching materials](https://afrimapr.github.io/afrimapr.website/training/) and even [publications of data](https://afrimapr.github.io/afrimapr.website/publications/) in journals.

The next phase of the talk was a sharing from [Clinton Nkolokosa](https://twitter.com/clintymw) about his experiences as a geospatial researcher doing projects such as [malaria incident](https://rpubs.com/Clinty/786191), [flood incidence](https://nkolokosa.shinyapps.io/FloodMapper/) and [covid 19 cases](https://rpubs.com/Clinty/705819). Such meaningful accomplishments were hard to obtain as he highlighted the challenges faced such as difficulties in getting up-to-date data (Clinton ended up having to update the data on his own) and finding local talented people (R gurus) doing similar work for help and consultation due to lack of funding and opportunities. He stressed the importance of more individuals from the African R community to step out of their comfort zones and be drivers of innovative ideas and resources.  

The following phase of the keynote is mainly focus on effective teaching. [Anne Treasure](https://twitter.com/annemtreasure) presented the usefulness of [learnr](https://rstudio.github.io/learnr/) to create [online tutorials](https://afrimapr.github.io/afrilearnr/) to support novice learners of R. She then showed how the team goes one step further by making these material more accessible such as 

* Teaching them in French, besides English.
* Use of [RStudio Cloud](https://rstudio.cloud/) so that more people can participate on the courses simultaneously.
* Making materials downloadable for local use.
* Pre and post course survey to understand the attendee's concern for improvement of future teaching sessions.

[Nono Gueye](https://twitter.com/gueyenono) then showed how having teaching resources in other language such as French can benefit more people in multilingual Africa and gave some existing R resources in French such as [tidyverse](https://juba.github.io/tidyverse/index.html).

The last phase of the keynote is about the status of R communities in Africa. Anelda showed some statistics that the R communities in Africa when compared to North America is not doing as well with a significantly lower number of active groups and organised events. This implies that the knowledge transmission of R from one individual to another in Africa is quite low. 

Anelda then gave a few reasons to explain why it is hard to build and sustain an R community. One reason is that building one requires a lot of skills and hard work which is daunting if the organising team just have a few people. Another reason is that the people who build such communities are mainly volunteers who may be overburdened by work and/or family commitments to run regular events. Low participate rate in such organised event does bring a mental toll on the organisers as well. The last reason is a lack of funding and resources.

The keynote concluded first by appealing to the African R community to support more new R users locally, collaborate locally and internationally and try to experiment new established approaches to see if it helps or not. It then appeal towards the global (funding) community to find ways to reward people for their time to run events, invest more in multilingual materials as well as to identify and support locally-led, custom-developed initiatives that works in emerging regions. 

* üìù[Slides](https://docs.google.com/presentation/d/1ResuITjWSs6shKT0wtyyWzR1llTIu-t4cOcPh1BsIII/edit#slide=id.g131a1a79661_0_0)

### Poster Presentation

#### renderthis

I first entered the Dissemination of Information room because I was curious about the [renderthis](https://jhelvy.github.io/renderthis/) presented by [John Paul Helveston](https://twitter.com/JohnHelveston). It was formally called xaringanBuilder, one of the extension of [Xaringan](https://github.com/yihui/xaringan). For those who are new to [Xaringan](https://github.com/yihui/xaringan), it is an alternative way to create presentation slides in html. A decent quick start guide can be found in Silvia Canel√≥n's blog post [Deploying xaringan Slides with GitHub Pages](https://www.silviacanelon.com/blog/2021-deploying-xaringan-slides/). Here is a link to the [Xaringan gallery](https://xaringan.gallery/) for other examples. To my knowledge, the other extension packages are [xaringanthemer](https://pkg.garrickadenbuie.com/xaringanthemer/) and [xaringanExtra](https://pkg.garrickadenbuie.com/xaringanExtra/).

It is eye opening to see how many different ways [Xaringan](https://github.com/yihui/xaringan) slides can be converted to using [renderthis](https://jhelvy.github.io/renderthis/). It goes from the usual html file, pdf file to even png images. Currently, I was following the instructions in Garrick Aden-Buie's blog post [Printing xaringan slides with chromote](https://www.garrickadenbuie.com/blog/print-xaringan-chromote/) to output the [Xaringan](https://github.com/yihui/xaringan) slides into pdf. Maybe I should try to see if I can do the same with [renderthis](https://jhelvy.github.io/renderthis/). With [renderthis](https://jhelvy.github.io/renderthis/), users can also specify which [Xaringan](https://github.com/yihui/xaringan) slides to be converted to. Future work involves able to output the [Xaringan](https://github.com/yihui/xaringan) slides as a Micosoft Powerpoint [3 slides per page handout](https://answers.microsoft.com/en-us/msoffice/forum/all/how-do-i-save-a-powerpoint-presentation-with/e93ec638-8ad1-4002-8c1c-78cc90f097a6).

#### animate

I jumped to Data Visualisation room later after that. 

I was looking forward for the presentation on the R package [animate](https://kcf-jackson.github.io/animate/index.html) by Jackson Kwok. You see, I was reading the poster in Micosoft Powerpoint beforehand and my jaws dropped when I see that the animation featured in this article titled [The New Science of Sentencing](https://www.themarshallproject.org/2015/08/04/the-new-science-of-sentencing) could be replicated using R. While reading the documentation of [animate](https://kcf-jackson.github.io/animate/index.html), I found out Jackson also made some [Xaringan](https://github.com/yihui/xaringan) [slides](https://rawcdn.githack.com/kcf-jackson/animate/0f3e8211f063e832b3b83288b4834329d491f4da/man/slides/SVI_presentation.html) introducing the R package [animate](https://kcf-jackson.github.io/animate/index.html). Do take a look if you need a more visual information. Unfortunately, when I entered the virtual longue. It just ended...

#### Polished Annotations

Putting this aside, the next presentation was by [Cara Thompson](https://twitter.com/cararthompson) sharing useful tips and trick to make polished annotations in [ggplot](https://ggplot2.tidyverse.org/index.html). Making annotations in [ggplot](https://ggplot2.tidyverse.org/index.html) has always been really challenging for me. I usually spend a lot of time tweaking fixed parameters to move the annotations from one place to another. Most of the time I just gave up and use Microsoft Powerpoint to add these extra text boxes. Cara's success in finding several clever strategies to make polished annotations, using [ggtext](https://wilkelab.org/ggtext/), [glue](https://glue.tidyverse.org/), CSS formatting and a filtered tibble with unique arrow curvature information, does makes me smile. Her tips can also be found in this [talk post](https://www.cararthompson.com/talks/user2022). One of her blog post [Alignment cheatsheet](https://www.cararthompson.com/posts/2021-09-02-alignment-cheat-sheet/) may be useful for those who need a little help on the alignment parameters.

#### Two-Sample Corrgram

The last presentation in the Data Visualisation room is by Rohan Tummala. This visualisation is a unique way to optimise the correlation results of dichotomous data within the space of a 2D heatmap matrix. More information can be found in this [project webpage](https://rithikatummala8.wixsite.com/sigmaxisrs2021/). 

It definitely has a lot of potential to be improved by the R community. Here are my "5-cent" suggestions. The team may wish to use the R package [correlation](https://easystats.github.io/correlation/) from the [easystats](https://easystats.github.io/easystats/) team, to expand their current correlation methods of Pearson, Kendall and Spearman. As for the question raised on extending the static plot to multichotomous data (or k-sample corrgram), one idea I can think of currently is to adopt the [scatter plot matrix](http://www.sthda.com/english/wiki/scatter-plot-matrices-r-base-graphs) style where the diagonal are the groups and the scatter plots are replaced with the two sample corrgrams instead. However, this in turn creates the same redundant space which the two-sample corrgram is supposed to prevent. Regardless, if this visualisation continue to receive good feedback, someone will create an interactive two-sample corrgram and push it as a web tool.

#### pacs

I next entered the R in Production room where I am first introduced to the R package [pacs]((https://polkas.github.io/pacs/)) by [Maciej Nasinski](https://github.com/polkas). It contains a set of useful utility functions for helping R package developers life easier such as, automating validation of a [renv](https://rstudio.github.io/renv/articles/renv.html) lock file, finding out packages which are not from CRAN and many more. More information can be found in its [documentation](https://polkas.github.io/pacs/).

#### svgtools

The second sharing is from Konrad Oberwimmer who introduced the R package [`svgtools`](https://cran.r-project.org/web/packages/svgtools/index.html) that is able to key in statistical results onto charts template made in [SVG file format](https://commons.wikimedia.org/wiki/Template:SVG_Chart). This is helpful if there is a need to create graphs that needs to follow a certain layout based on corporate needs.

#### data.validator

The next showcase is about [data.validator](https://appsilon.github.io/data.validator/) by [Marcin Dubel](https://twitter.com/DubelMarcin). Honestly, this is an R package that I wish I knew earlier how to use it. While it is great to have tools that validate the data but it is even better when a validation report, highlighting the possible issues of a given dataset clearly and explicitly, can be created and distributed to others. [data.validator](https://appsilon.github.io/data.validator/) not only uses [assertr](https://github.com/ropensci/assertr) to do the validation but is able to create an interactive report in html as well. More details can also be found in this [youtube video](https://www.youtube.com/watch?v=U1-j7c_8LFQ) as well as this [R-bloggers post](https://www.r-bloggers.com/2022/05/data-cleaning-in-r-2-r-packages-to-clean-and-validate-datasets/)

#### Continuous Integration In GitLab For R

Lastly, it is a workflow presented by [Cody Marquart](https://twitter.com/cody_marquart) on how to manage R packages automatically using [GitLab](https://about.gitlab.com/) Continuous Integration (CI). [GitLab CI](https://docs.gitlab.com/ee/ci/introduction/index.html#continuous-integration) was first introduced from an [April 2020 GitLab meetup](https://www.youtube.com/watch?v=l5705U8s_nQ&t=397s). It is nice to know that CI is possible to be applied on R packages management in GitLab. Usually, CI was done using [Github Actions](https://github.com/features/actions) from [Github](https://github.com/) because of many [useful resources](https://github.com/r-lib/actions) available to help users create CI tasks easily. Thus, [Github Actions](https://github.com/features/actions) became a popular choice for R package management. Nevertheless, as it is unwise not to have a backup plan, being aware of that an alternative workflow exists is critical. Take a look at one of GitLab CI examples used in the R package [shinyLogger](https://gitlab.com/clmarquart/shinyLogger/-/blob/main/.gitlab-ci.yml) 
Hopefully, I will get to witness a similar workflow for managing R packages in [Bitbucket](https://bitbucket.org/product/) in the future. 

### Clinical Data Review Reporting Tool

Day 3 for me was filled with many sessions that I was interested in like Data Visualization, Publishing and Reproducibility as well as Web Frameworks. Unfortunately, I could not join all at the same time. After some thoughts, I had decided to attend the session on Publishing and Reproducibility.

The first talk was from Laure Cougnaud from [OpenAnalytics](https://www.openanalytics.eu) introducing an R package [clinDataReview](https://cran.r-project.org/web/packages/clinDataReview/index.html) used to provide a medical report in [bookdown](https://bookdown.org/), filled with interactive plots to understand how patients are doing during a clinical study. An example of this report can be found in this [link](https://medical-monitoring.openanalytics.io/) The report is created as a folder of mainly HTML (and [other](https://cran.r-project.org/web/packages/clinDataReview/vignettes/clinDataReview-reporting.html)) files which is then distributed to the clinicians. The key to making this possible is the use of a standard template report in R markdown as well as a configuration file in YAML for users to set specific parameters to make the report customisable and flexible to their needs.

I was first introduced to Rmarkdown report templates during my attendance in the RStudio Conference 2020 at San Francisco. It was presented by [Sharla Gelfand](https://twitter.com/sharlagelfand) titled [Don‚Äôt repeat yourself, talk to yourself! Reporting with R](https://www.youtube.com/watch?v=JThd3YYQXGg&ab_channel=RStudio). I highly recommend watching as it is really down to Earth and funny at the same time. Sharla also provided a [blog post](https://sharla.party/post/usethis-for-reporting/) showing step by step how to produce an introductory R package with Rmarkdown report templates. The work done by Laure Cougnaud and her team is bringing this workflow to the next level by extending from Rmarkdown to [bookdown](https://bookdown.org/) reports. Definitely a job well done.

* üìù[Slides](https://medical-monitoring.openanalytics.io/)

### knitr engines And blogdown Troubleshooting

The next talk is by [Christophe Dervieux](https://twitter.com/chrisderv) giving a [introductory tour](https://cderv.rbind.io/talk/2022-user-knitr-engines/) on the different [knitr](https://github.com/yihui/knitr) engines. The [knitr](https://github.com/yihui/knitr) engines can be listed in R using the command `names(knitr::knit_engines$get())`. More information of commonly used engines can be found in the [Rmarkdown e-book](https://bookdown.org/yihui/rmarkdown/language-engines.html. The talk also introduced the latest [`knitr`](https://github.com/yihui/knitr) engine called `exec` which allow command lines to be executed in the Rmarkdown code chunk. The talk also inform users how to create custom [knitr](https://github.com/yihui/knitr) engines as well. One major takeaway for me on this talk is the that there is actually a [Github link](https://github.com/yihui/knitr-examples) showing Rmarkdown examples of many different [knitr](https://github.com/yihui/knitr) engine, including the latest `exec` engine found [here](https://github.com/yihui/knitr-examples/blob/master/124-exec-engine.Rmd). 

After enjoying the tour on [knitr](https://github.com/yihui/knitr) engines, the session proceeds with [Yihui Xie](https://twitter.com/xieyihui) sharing some [helpful summary](https://yihui.org/en/2022/06/user-blogdown/) on how to create a blog using [blogdown](https://pkgs.rstudio.com/blogdown/) with minimal issues using `blogdown::serve_site()` and `blogdown::check_site()`. Hopefully the `blogdown::check_site()` could be part of the RStudio Addins for [blogdown](https://pkgs.rstudio.com/blogdown/) in the future. 

For me, I started to learn how to create this [Hugo Ap√©ro](https://hugo-apero-docs.netlify.app/) theme [blogdown](https://pkgs.rstudio.com/blogdown/) site from watching a YouTube video of a [lesson](https://www.youtube.com/watch?v=RksaNh5Ywbo&ab_channel=R-LadiesTunis) conducted by Alison Hill's in R Ladies Tunis. However, if a two hours lesson is too long, may I direct you to Alison Hill's [Day 09: Hugo Ap√©ro from scratch || rmarkdown + blogdown + Netlify](https://www.youtube.com/watch?v=yXFu_upDL2o&ab_channel=AlisonHill) from the #12DaysOfDusting [series](https://www.youtube.com/playlist?list=PLzxicn7kBeazI9Niimsth81iWn4mvCmu0) instead.

* üìù[Christophe's Slides](https://cderv.rbind.io/talk/2022-user-knitr-engines/)
* üìù[Yihui's Slides](https://yihui.org/en/2022/06/user-blogdown/)

### Reliable Scientific Software Development

The last presentation of this session is by [Meike Steinhilber](https://twitter.com/M_Steinhilber), developer of the R packages [sprtt](https://meikesteinhilber.github.io/sprtt/)(Sequential Probability Ratio Tests Using The Associated t-statistic) and its Shiny counterpart [sprit](https://meike-steinhilber.shinyapps.io/spirit/). The talk focuses on ways to develop reliable scientific software using some best practices for software development. 

In summary, the best practices are having clean and refactored code, software testing, continuous integration, version control and extended documentation. Examples used were from her R package [sprtt](https://meikesteinhilber.github.io/sprtt/). This is great advice for someone who has just started to have many long R scripts and wish to make them more manageable and sustainable. As this is also the speaker's [first conference presentation](https://twitter.com/M_Steinhilber/status/1539705226319564802?cxt=HHwWhMC4mdzvkN4qAAAA), do show her some love and support if you like the presentation.

This presentation gives me a nostalgia feeling as I have [presented](https://jeremy-selva.netlify.app/talk/2021-10-29-pydata-global-2021/) something similar in the [PyData Global 2021](https://pydata.org/global2021/) conference using a Python-made software [MSOrganiser](https://github.com/SLINGhub/MSOrganiser) as an example. That conference was also my first as well. Instead of reliability, the focus of my presentation however was tips to make the software more user friendly, less intimidating for new users and ways to deal with the angry ones as well.

* üìù[Slides](https://www.dropbox.com/s/dv80062qo0rbhd3/useR_MeikeSteinhilber_2022_V2.pdf?dl=0)

### Second Keynote: Applied Machine Learning With tidymodels

Day 3 of the conference ended with a keynote from [Julia Silge](https://twitter.com/juliasilge), author of [Supervised Machine Learning for Text Analysis in R](https://smltar.com/). She also posted a lot of [tidymodels-related lessons](https://www.youtube.com/c/JuliaSilge/videos) on YouTube as well as the online tutorial [Text mining with tidy data principles](https://juliasilge.shinyapps.io/learntidytext/).

The keynote consisted of a brief introduction of [machine learning](https://vas3k.com/blog/machine_learning/), followed by the e-book [Tidy Modeling with R](https://www.tmwr.org/) which she is working on. Julia then presented three things that made the job of a machine learning practitioner challenging and showed how [tidymodels](https://www.tidymodels.org/) was able to help the practitioner cope with those challenges.

The first challenge for a machine learning practitioner is to decide how much data should be used as training data to train the model and how much is used as test data to evaluate the model. If we allocate too much on training data, we will have a model that is unable to generalize well on new, unseen data. On the other hand, allocating too much on the test data will give an unoptimised model that gives inconsistent predictions on input data with similar properties. The [tidymodels](https://www.tidymodels.org/) package best suited for is [rsample](https://rsample.tidymodels.org/) which provides not just data splitting between training and testing data but also resampling of the training data (simulated versions of training data) by cross validation or bootstrapping for the optimisation of the model's complex parameters.    
Another tough decision a machine learning practitioner has to make is to determine when does the model building process starts and ends. To do this, a proper model building workflow is required. A common misconception is the belief that the model building process starts only when we started using a given model to fit the training data. Julia warned that such a workflow is susceptible to [data leakage](https://machinelearningmastery.com/data-leakage-machine-learning/). Instead, the model building workflow should include any preprocessing steps, feature engineering processes, the model fit itself and post-processing activities. However, managing such a complex workflow can be hard, especially when many [different kinds of models](https://towardsdatascience.com/all-machine-learning-models-explained-in-6-minutes-9fe30ff6776a) are used. As such, the [recipes](https://recipes.tidymodels.org/) and [workflows](https://workflows.tidymodels.org) R packages from [tidymodels](https://www.tidymodels.org/) are created to assist machine learning practitioners to better organise their machine learning related projects.

After finalising the machine learning model, the machine learning practitioner can now deploy the model into the external clients system. However, the work does not end here. Overtime, the deployed model may decrease its effectiveness in making good predictions because the properties of input data have changed. The machine learning practitioner must monitor the model and wisely determine when it is the time to collect new data to create an updated model that performs better than the previous one. As many versions of models are created, a report may be required from the external clients to give transparency on how well different models are doing when compared to its predecessor. This process of model maintenance is also called Machine Learning Operations or MLOps for short.

To facilitate a smooth MLOps process for the programming language of Python and R, the last R package that Julia introduced is [vetiver](https://vetiver.rstudio.com/). 
[vetiver](https://vetiver.rstudio.com/) automatically generates [Dockerfiles](https://www.simplilearn.com/tutorials/docker-tutorial/what-is-dockerfile) so that the trained model can be deployed easily. Moreover, [vetiver](https://vetiver.rstudio.com/) is able to create APIs for the machine learning practitioner to monitor how well the trained model as well as the option to provide a [report card](https://vetiver.rstudio.com/learn-more/model-card.html) to summarise how the model is doing over time. In suumary, [vetiver](https://vetiver.rstudio.com/) is an open source tool created to provide a decent framework to version, share, deploy, and monitor a trained model.

The keynote is indeed rich in content regarding the best practices for machine learning. 

* üìù[Slides](https://www.dropbox.com/s/3ds01k9hdtn2ghb/user2022.pdf?dl=0)

## Day 4

### First Keynote: Junior R-core Experiences

Day 4 of the conference started with a keynote by the R Core Team. The keynote is led by [Sebastian Meyer](https://twitter.com/bastistician) who has recently joined the R Core team. 

The first part of the presentation is about a summary of the [major changes](https://journal.r-project.org/archive/2021-2/core.pdf) in R from version 4.1.3 version 4.2.0, such as [code highlighting in HTML documentation](https://blog.r-project.org/2022/04/08/enhancements-to-html-documentation/index.html) and a new function [Sys.setLanguage](https://stat.ethz.ch/R-manual/R-devel/library/base/html/gettext.html) that is able to change the language of messages from R. It is from this part of the keynote that I learnt there is actually a [search engine](https://search.r-project.org/) for R related functions from CRAN packages. Do take a look at the [R blog](https://blog.r-project.org/) for updates on the latest developments in R.

The second part is a sharing of a few bug report stories followed by some tips on anyone who wish to contribute and make R better. R actually has a website [R's Bugzilla](https://www.r-project.org/bugs.html) for reporting potential bugs as well as a simple [walkthrough](https://blog.r-project.org/2019/10/09/r-can-use-your-help-reviewing-bug-reports/index.html) of how to create a decent [bug report](https://www.r-project.org/bugs.html). The presenter then requests for more people to test R, especially its [pre-release versions](https://blog.r-project.org/2021/04/28/r-can-use-your-help-testing-r-before-release/index.html), as well as to report to the R-core team old bug reports in [R's Bugzilla](https://www.r-project.org/bugs.html) which may have already been resolved with a later version of R.

After the keynote session, the R Core Team then had a panel discussion.

* üìù[Slides](https://raw.github.com/JauntyJJS/jaunty-blogdown/main/content/blog/2022-06-23-UseR-2022/R_core.pdf)

### Package Dependencies

After the panel discussion, I attended the first two talks in the Package Development session followed by the last two talks in Building the R Community 2.

The first talk on Package Development is from [Zuguang Gu](https://twitter.com/jokergoo_gu), developer of many packages such as [ComplexHeatmap](https://github.com/jokergoo/ComplexHeatmap) and [spiralize](https://github.com/jokergoo/spiralize). The presentation is about an R package called [pkgndep](https://jokergoo.github.io/pkgndep/) used to calculate the dependency heaviness of an R package and display the results in a heatmap. 

When developing R packages, it is advisable to keep it [lightweight](https://tinyverse.netlify.app/) (depend on a low number of external R packages). This is mainly to allow users to install R packages easily by reducing the chances of failure due to an unsuccessful dependency installation. Thus, [pkgndep](https://jokergoo.github.io/pkgndep/) is helpful for R package developers who wish to optimise their R package dependencies.

This is kind of similar to the R package [dstr](https://github.com/falo0/dstr). The difference is that [pkgndep](https://jokergoo.github.io/pkgndep/) provides a more detailed result in a heatmap rather than a network graph. On the other hand, [dstr](https://github.com/falo0/dstr) provides clearer advise to the R developers on what they can do next to reduce the dependencies. Perhaps, the teams of [pkgndep](https://jokergoo.github.io/pkgndep/) and [dstr](https://github.com/falo0/dstr) can collaborate and build on each other strengths to further improve on the usefulness of their current creations.

* üìù[Slides](https://docs.google.com/presentation/d/11EwFl18Ana1pZ1C4UDdbdqjLJnbM9F32KOHXRpbY4IM/edit#slide=id.p)

### pre-commits

The second talk conducted by [Lorenz Walthert](https://twitter.com/lorenzwalthert) is an eye-opener for me as I am unfamiliar with git pre-commit hooks. From my understanding, pre-commit hooks are widely used for Python developers due to the availability of of the Python package [pre-commit](https://pre-commit.com/) to do all the heavy lifting.
Motivated by how useful git pre-commit hooks are in improving code quality, Lorenz created a R package [precommit](https://lorenzwalthert.github.io/precommit/index.html) in hopes that more R package developers are able to adapt this workflow easily.

* üìù[Slides](https://github.com/lorenzwalthert/useR2022.precommit.slides)
* üìù[Demo](https://github.com/lorenzwalthert/useR2022.precommit.demo)

### Transitioning To R

After the second talk, I jumped to the session on Building the R Community 2. Luckily, this time when I got in, the third talk of the session has just begun. It was a presentation by [Kieran Martin](https://twitter.com/kjmartinstats) from [Roche](https://twitter.com/Roche). I have watched a previous R Consortium conducted by his team before in YouTube titled [Package Management at Roche]((https://www.youtube.com/watch?v=A8ePOTOSGg0&ab_channel=RConsortium)) and find it very informative and educational.

It is delightful to see him again presenting for useR! 2022. This time Kieran shared his experience on his large Product Development team's ongoing journey to using R as one of the core data science tool, when there is a need to report results of clinical trials in the most efficient way. Best practices were shared like using [Docker](https://www.docker.com/) to fix the operating system, [renv](https://rstudio.github.io/renv/index.html) and internal package repositories to control the R packages used and the [R Validation Hub](https://www.pharmar.org/) to validate R packages. He also provided some useful advice and mistakes to avoid to help people grow into R.

What is very touching is their desire in conjunction with like-minded pharmaceutical companies to create a shared set of high quality R packages for clinical reporting related analysis, plotting table and graphs via the [pharmaverse](https://pharmaverse.org/) and [Insights Engineering](https://github.com/insightsengineering). At least we do not have to see multiple R packages solving the same problem. Definitely something great to look into.

### Reflections of a Research Software Engineer

This is followed by a presentation by [Nicholas Tierney](https://twitter.com/nj_tierney), a [research software engineer](https://researchsoftware.org/) at the [Telethon Kids Institute](https://www.telethonkids.org.au/). Nicholas is also the developer of the two data visualisation R packages [visdat](https://docs.ropensci.org/visdat/) and [naniar](https://naniar.njtierney.com/index.html).

The talk is consist of three parts: what kind of work he does as a [research software engineer]((https://researchsoftware.org/), a small summary of how he tries to maintain the [greta](https://greta-stats.org/) R package (as part of his job scope) and the future of [research software engineer](https://researchsoftware.org/) in Australia.

I do gain some useful knowledge in package management such as creating better snapshot test, efficient pull request using `pr_feteh` and `pr_finish` from the [usethis](https://usethis.r-lib.org/reference/pull-requests.html) R package and using [glue](https://glue.tidyverse.org/) to make better command line messages to users.

Despite being busy with his research software engineer role, Nicholas is also active in the [rOpenSci Social Coworking and Office Hours](https://ropensci.org/events/coworking-2022-06/) (Asia Pacific Edition) helping people with R related issues. It is actually from this online event when I first met him. He is really a nice and approachable R enthusiast.

* üìù[Slides](https://njt-user-2022.netlify.app/)

### Synthetic Data Generation

Honestly the last set of sessions was another hard choice for me as it covers topics that I am unfamiliar with. I took a leap of faith and attended the session on Synthetic Data and Text Analysis.

The first talk is about a small introduction of the [simPop](https://github.com/statistikat/simPop) R package by Alexander Kowarik. It is an R package used to create synthetic data. Synthetic data generation is useful when there is a need to transform sensitive but complex original data to into privacy-compliant data that still retains the complex structure of the original data. The transformed data can then be used for train machine learning models, software testing and simulation studies. This is actually my first time getting to know about synthetic data and what it is used for. I am grateful for the speaker for giving such a clear presentation for me to understand.

### textrecipes To Improve Preprocessing Of Textual Data

The second one switches to the topic of Text Analysis with the R package [textrecipes](https://textrecipes.tidymodels.org/). It is presented by [Emil Hvitfeldt](https://twitter.com/Emil_Hvitfeldt) one of the authors of the e-book [Supervised Machine Learning for Test Analysis in R](https://smltar.com/). While I am new to text data analysis, I am able to understand the unique properties of such dataset and why is it so hard to transform such a dataset into meaningful numbers that a machine learning model can use to learn. The presentation then shows step by step how [textrecipes](https://textrecipes.tidymodels.org/) is able to make this transformation process less painful and yet flexible to user's different needs.

As someone who has attended a [book club](https://www.youtube.com/watch?v=cXjTKOoN6aU&list=PL3x6DOfs2NGisLSs09v1NQUQaxuE8nbOO) on [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)(ISLR) conducted by the [R4DS Online Learning Community](https://www.rfordatasci.com/), Emil's [ISLR tidymodels Labs](https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/index.html) notes have been very helpful to our cohort group's learning journey to use [tidymodels](https://www.tidymodels.org/) to better understand some of the statistical learning methods.

* üìù[Slides](https://emilhvitfeldt.github.io/useR2022-textrecipes)

### Bivariate Data Generation Using Scagnostics

The next presentation is led by [Janith Wanniarachchi](https://mobile.twitter.com/janithcwanni) regarding his R package called [scatteR](https://github.com/janithwanni/scatteR). [scatteR](https://github.com/janithwanni/scatteR) is used to generate a bivariate data set based on a given [scagnostics](https://en.wikipedia.org/wiki/Scagnostics) measurement. 

I enjoyed the flow of the presentation as it is like telling a story. The protagonist who faced a stumbling block along the way managed to overcome it after being inspired by ice-cream sprinkles. I won't spoil the plot any further.

Janith is another [first time](https://mobile.twitter.com/janithcwanni/status/1540053289089519616?cxt=HHwWgMDS9dGTr98qAAAA) presenter at an international conference. Do show him your support if you like his presentation. 

* üìù[Slides](https://scatter-use-r-2022.netlify.app/)

### Making Better Forecasting Models By Integrating Sentiment Analysis With Topic Modeling

The last talk of the session is quite hard for me to understand because I am unfamiliar with textual data analysis as mentioned before. Nevertheless, to the best of my knowledge, I try to explain what is going on. 

Oliver Delmarcelle shows how the R package [sentopics](https://github.com/odelmarcelle/sentopics) can be used to integrating sentiment analysis and topic modeling of textual data to potentially make better forecasting models. In this presentation, the [press conferences](https://www.ecb.europa.eu/press/key/html/index.en.html) documents of the European Central Bank is used as an example.

If you are unfamiliar with the term topic modeling and sentiment analysis, take a look at these two Youtube videos by [Julia Silge](https://twitter.com/juliasilge)
[Data Centric Inc.](https://www.datacentriccorp.com/) to know what they are.

* [Topic modeling with R and tidy data principles](https://www.youtube.com/watch?v=evTuL-RcRpc)
* [A Tutorial on Sentiment Analysis in R](https://www.youtube.com/watch?v=c7YSyCofH3o)

The [press conferences](https://www.ecb.europa.eu/press/key/html/index.en.html) documents of the European Central Bank are first grouped into different dominant topics/themes, like inflation, economic growth and so on. Separately, sentiment analysis is applied on the [press conferences](https://www.ecb.europa.eu/press/key/html/index.en.html) documents to obtain two sentiment time series data, the sentiment of the Economic Condition and Monetary Policy over time. 

With that, two forecasting models were constructed to see which one better predict the [European Central Bank's decision](https://www.ecb.europa.eu/press/govcdec/html/index.en.html) on the interest rate and monthly targets of the asset purchase program. They ar a forecasting model using only the two sentiment predictors (Economic Condition and Monetary Policy) and another one with an additional topic-specific sentiment predictor. The result shows that the additional topic-specific sentiment predictor improves the forecasting model.  

In addition, Oliver also showed how [sentopics](https://github.com/odelmarcelle/sentopics) is able to create time series plots showing how each topic/theme contributed to the sentiment of the Economic Condition.

### Second Keynote: Teaching Accessibly And Teaching Accessibility

[Mine Dogucu](https://twitter.com/MineDogucu), one of the authors of the e-book [Bayes Rules! An Introduction to Applied Bayesian Modeling](https://www.bayesrulesbook.com/) , delivered the last keynote of the day titled Teaching Accessibly and Teaching Accessibility. The talk consist of three parts: Teaching Accessibly, Teaching Accessibility and some recommendations for the community, especially those involved in pedagogy.

To make teaching resources more accessible and inclusive, Mine first suggested that such education materials should be open access (made available on the internet) as not all students are fortunate financially to be able to afford textbook material. In addition, students are usually the ones that contributes the most in improving the quality the of education materials by highlighting mistakes and providing alternative solutions to exercises. Such opportunities may missed out if the education materials remain only on print.

Even when the teaching material is available online, accessibility can be further expanded to the visually impaired with the use of [alternative text](https://www.med.unc.edu/webguide/accessibility/alt-text/) and [screen readers](https://www.nomensa.com/blog/what-screen-reader). Being a strong advocate for accessible teaching, Mine went the extra mile by opening a [feature request](https://github.com/rstudio/rmarkdown/issues/1867) for [Rmarkdown](https://rmarkdown.rstudio.com/) to include an option of alternative text in 2020.

As the content of the Bayesian statistics e-book requires a strong mathematics background to comprehend, Mine tries to make lessons more inviting for readers new to Bayesian statistics by complementing mathematical concepts with story telling, step by step computing instructions and the use relevant examples (Weather, Spotify data, Hotel bookings) that most lay person can relate. The goal is to encourage learners to embrace a growth mindset by learning from mistakes and not be discouraged when things are unclear when seen for the first time. Mistakes can still be good if it teaches you something. More ways to make teaching material accessible can be found the paper  [Framework for Accessible and Inclusive Teaching Materials for Statistics and Data Science Courses](https://arxiv.org/abs/2110.06355) 

When she had finished writing the e-book, Mine began to realise how little she knew about accessibility and was curious to know why this is so. She decided to look back into past teaching curriculum and data analysis tools to see how much focus on accessibility awareness and support are there. Unfortunately, most had little to no support. Knowing what needs to be done, she seek the support of [Teach Access](https://teachaccess.org/) and motivated individuals like [JooYoung Seo](https://twitter.com/seo_jooyoung) to spread the need of accessibility skills in data science education for aspiring and experienced data scientist. Mine is currently working on designing curriculum to include accessibility awareness and use of assistive technologies in data science projects.

Mine proceeds with some technical details on how to use R to make data visualisation more accessible. Examples are 

* [colorblindr](https://github.com/clauswilke/colorblindr) to simulate colour blindness and utilisation of the [Okabe-Ito](https://jfly.uni-koeln.de/color/) palette, 
* Image alternative text in [Rmarkdown](https://rmarkdown.rstudio.com/) with `fig.alt`. See this blog [post](https://www.rstudio.com/blog/knitr-fig-alt/) for more details. 
* [Data sonification](https://www.youtube.com/watch?v=1VS9Od9qM1k&ab_channel=ChandraX-rayObservatory) with [sonify](https://cran.r-project.org/web/packages/sonify/index.html), 
* [Data tactualization](https://www.youtube.com/watch?v=ClI555l4Z1M&ab_channel=JooYoungSeo) with [tactileR](https://github.com/jooyoungseo/tactileR)

For image alternative text, take a look at Amy Cesal's [post](https://medium.com/nightingale/writing-alt-text-for-data-visualization-2a218ef43f81) on some good practice guidelines to describe plots with alternative text. One can also use the `VI` function from the [BrailleR](https://github.com/ajrgodfrey/BrailleR) package to generate [alternative text automatically](https://cran.rstudio.com/web/packages/BrailleR/vignettes/qplot.html). More resources on accessibility can be found in this [presentation](https://www.youtube.com/watch?v=0HvyNtltu-A&ab_channel=RStudio) on accessible data science on the RStudio Global Conference 2021 by Mine's collaborator, [JooYoung Seo](https://twitter.com/seo_jooyoung). 

Mine concluded the keynote with many recommendations for the community. Here are some points that I have summarised below

* Having alternative text in a picture is worth a thousand picture and should be treated with greater value than a diagram without one. Thus, writing alternative text as a git pull request is a good way to contribute to open source educational material.

* Event organisers should take a more proactive approach by creating events/meetups that are more accommodating to the needs of individuals who need additional accessibility and not wait for them to make such a request before working on it. 

* Providing accessibility related support should not be a job assigned to volunteers alone. Event organisers must invest some resources in hiring professionals to lead and guide these volunteers and ensure that these services are implemented correctly. 

* Accessibility lessons should be taught to students as well as professionals, included in all programming languages, and applicable outside of the data science classroom. Given a (school or) work project, (students and) professionals should be (assessed and) held accountable for their accessibility practices.

* Accessibility should be seen as a gift for everyone and not for a privileged few.

* üìù[Slides](https://mdogucu.github.io/user2022)

