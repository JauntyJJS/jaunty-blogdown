@article{PARAGON-HF,
  title = {Angiotensin–Neprilysin Inhibition in Heart Failure with Preserved Ejection Fraction},
  author = {Solomon, Scott D. and McMurray, John J.V. and Anand, Inder S. and Ge, Junbo and Lam, Carolyn S.P. and Maggioni, Aldo P. and Martinez, Felipe and Packer, Milton and Pfeffer, Marc A. and Pieske, Burkert and Redfield, Margaret M. and Rouleau, Jean L. and van Veldhuisen, Dirk J. and Zannad, Faiez and Zile, Michael R. and Desai, Akshay S. and Claggett, Brian and Jhund, Pardeep S. and Boytsov, Sergey A. and Comin-Colet, Josep and Cleland, John and D\"{u}ngen, Hans-Dirk and Goncalvesova, Eva and Katova, Tzvetana and Kerr Saraiva, Jose F. and Lelonek, Ma\l{}gorzata and Merkely, Bela and Senni, Michele and Shah, Sanjiv J. and Zhou, Jingmin and Rizkala, Adel R. and Gong, Jianjian and Shi, Victor C. and Lefkowitz, Martin P.},
  journal = {New England Journal of Medicine},
  volume = {381},
  number = {17},
  pages = {1609-1620},
  year = {2019},
  doi = {10.1056/NEJMoa1908655},
  eprint = {https://doi.org/10.1056/NEJMoa1908655},
  note ={PMID: 31475794},
  url = {https://doi.org/10.1056/NEJMoa1908655}
}

@article{GALACTIC-HF,
  title = {Cardiac Myosin Activation with Omecamtiv Mecarbil in Systolic Heart Failure},
  author = {Teerlink, John R. and Diaz, Rafael and Felker, G. Michael and McMurray, John J.V. and Metra, Marco and Solomon, Scott D. and Adams, Kirkwood F. and Anand, Inder and Arias-Mendoza, Alexandra and Biering-S\o{}rensen, Tor and B\"{o}hm, Michael and Bonderman, Diana and Cleland, John G.F. and Corbalan, Ramon and Crespo-Leiro, Maria G. and Dahlstr\"{o}m, Ulf and Echeverria, Luis E. and Fang, James C. and Filippatos, Gerasimos and Fonseca, C\^{a}ndida and Goncalvesova, Eva and Goudev, Assen R. and Howlett, Jonathan G. and Lanfear, David E. and Li, Jing and Lund, Mayanna and Macdonald, Peter and Mareev, Viacheslav and Momomura, Shin-ichi and O’Meara, Eileen and Parkhomenko, Alexander and Ponikowski, Piotr and Ramires, Felix J.A. and Serpytis, Pranas and Sliwa, Karen and Spinar, Jindrich and Suter, Thomas M. and Tomcsanyi, Janos and Vandekerckhove, Hans and Vinereanu, Dragos and Voors, Adriaan A. and Yilmaz, Mehmet B. and Zannad, Faiez and Sharpsten, Lucie and Legg, Jason C. and Varin, Claire and Honarpour, Narimon and Abbasi, Siddique A. and Malik, Fady I. and Kurtz, Christopher E.},
  journal = {New England Journal of Medicine},
  volume = {384},
  number = {2},
  pages = {105-116},
  year = {2021},
  doi = {10.1056/NEJMoa2025797},
  eprint = {https://doi.org/10.1056/NEJMoa2025797},
  note ={PMID: 33185990},
  url = {https://doi.org/10.1056/NEJMoa2025797}
}

@article{Padam-pvalue,
  title = {P Value, Statistical Significance and Clinical Significance},
  author = {Singh Padam},
  journal = {Journal of Clinical and Preventive Cardiology},
  volume = {2},
  number = {4},
  pages = {202-204},
  year = {2013},
  url = {https://www.jcpcarchives.org/full/p-value-statistical-significance-and-clinical-significance-121.php}
}

@article{Rogers-Joint-Model,
  author = {Rogers, Jennifer K. and Yaroshinsky, Alex and Pocock, Stuart J. and Stokar, David and Pogoda, Janice},
  title = {Analysis of recurrent events with an associated informative dropout time: Application of the joint frailty model},
  journal = {Statistics in Medicine},
  volume = {35},
  number = {13},
  pages = {2195-2205},
  year = {2016},
  keywords = {recurrent events, dependent censoring, joint frailty models, heart failure},
  abstract = {This paper considers the analysis of a repeat event outcome in clinical trials of chronic diseases in the context of dependent censoring (e.g. mortality). It has particular application in the context of recurrent heart failure hospitalisations in trials of heart failure. Semi-parametric joint frailty models (JFMs) simultaneously analyse recurrent heart failure hospitalisations and time to cardiovascular death, estimating distinct hazard ratios whilst individual-specific latent variables induce associations between the two processes. A simulation study was carried out to assess the suitability of the JFM versus marginal analyses of recurrent events and cardiovascular death using standard methods. Hazard ratios were consistently overestimated when marginal models were used, whilst the JFM produced good, well-estimated results. An application to the Candesartan in Heart failure: Assessment of Reduction in Mortality and morbidity programme was considered. The JFM gave unbiased estimates of treatment effects in the presence of dependent censoring. We advocate the use of the JFM for future trials that consider recurrent events as the primary outcome. © 2016 The Authors. Statistics in Medicine Published by John Wiley \& Sons Ltd.},
  doi = {https://doi.org/10.1002/sim.6853},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.6853},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.6853}
}

@article{LWYY-Model,
  author = {Lin, D. Y. and Wei, L. J. and Yang, I. and Ying, Z.},
  title = "{Semiparametric Regression for the Mean and Rate Functions of Recurrent Events}",
  journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume = {62},
  number = {4},
  pages = {711-730},
  year = {2002},
  month = {01},
  abstract = "{The counting process with the Cox-type intensity function has been commonly used to analyse recurrent event data. This model essentially assumes that the underlying counting process is a time-transformed Poisson process and that the covariates have multiplicative effects on the mean and rate function of the counting process. Recently, Pepe and Cai, and Lawless and co-workers have proposed semiparametric procedures for making inferences about the mean and rate function of the counting process without the Poisson-type assumption. In this paper, we provide a rigorous justification of such robust procedures through modern empirical process theory. Furthermore, we present an approach to constructing simultaneous confidence bands for the mean function and describe a class of graphical and numerical techniques for checking the adequacy of the fitted mean–rate model. The advantages of the robust procedures are demonstrated through simulation studies. An illustration with multiple-infection data taken from a clinical study on chronic granulomatous disease is also provided.}",
  issn = {1369-7412},
  doi = {10.1111/1467-9868.00259},
  url = {https://doi.org/10.1111/1467-9868.00259},
  eprint = {https://academic.oup.com/jrsssb/article-pdf/62/4/711/49589776/jrsssb\_62\_4\_711.pdf}
}

@article{DELIVER-HF,
  author = {Jhund, Pardeep S. and Claggett, Brian L. and Talebi, Atefeh and Butt, Jawad H. and Gasparyan, Samvel B. and Wei, Lee-Jen and McCaw, Zachary R. and Wilderäng, Ulrica and Bengtsson, Olof and Desai, Akshay S. and Petersson, Magnus and Langkilde, Anna Maria and de Boer, Rudolf A. and Hernandez, Adrian F. and Inzucchi, Silvio E. and Kosiborod, Mikhail N. and Lam, Carolyn S. P. and Martinez, Felipe A. and Shah, Sanjiv J. and Vaduganathan, Muthiah and Solomon, Scott D. and McMurray, John J. V.},
  title = "{Effect of Dapagliflozin on Total Heart Failure Events in Patients With Heart Failure With Mildly Reduced or Preserved Ejection Fraction: A Prespecified Analysis of the DELIVER Trial}",
  journal = {JAMA Cardiology},
  volume = {8},
  number = {6},
  pages = {554-563},
  year = {2023},
  month = {06},
  abstract = "{In the Dapagliflozin Evaluation to Improve the Lives of Patients With Preserved Ejection Fraction Heart Failure (DELIVER) trial, dapagliflozin reduced the risk of time to first worsening heart failure (HF) event or cardiovascular death in patients with HF with mildly reduced or preserved ejection fraction (EF).To evaluate the effect of dapagliflozin on total (ie, first and recurrent) HF events and cardiovascular death in this population.In this prespecified analysis of the DELIVER trial, the proportional rates approach of Lin, Wei, Yang, and Ying (LWYY) and a joint frailty model were used to examine the effect of dapagliflozin on total HF events and cardiovascular death. Several subgroups were examined to test for heterogeneity in the effect of dapagliflozin, including left ventricular EF. Participants were enrolled from August 2018 to December 2020, and data were analyzed from August to October 2022.Dapagliflozin, 10 mg, once daily or matching placebo.The outcome was total episodes of worsening HF (hospitalization for HF or urgent HF visit requiring intravenous HF therapies) and cardiovascular death.Of 6263 included patients, 2747 (43.9\\%) were women, and the mean (SD) age was 71.7 (9.6) years. There were 1057 HF events and cardiovascular deaths in the placebo group compared with 815 in the dapagliflozin group. Patients with more HF events had features of more severe HF, such as higher N-terminal pro–B-type natriuretic peptide level, worse kidney function, more prior HF hospitalizations, and longer duration of HF, although EF was similar to those with no HF events. In the LWYY model, the rate ratio for total HF events and cardiovascular death for dapagliflozin compared with placebo was 0.77 (95\\% CI, 0.67-0.89; P \\&lt; .001) compared with a hazard ratio of 0.82 (95\\% CI, 0.73-0.92; P \\&lt; .001) in a traditional time to first event analysis. In the joint frailty model, the rate ratio was 0.72 (95\\% CI, 0.65-0.81; P \\&lt; .001) for total HF events and 0.87 (95\\% CI, 0.72-1.05; P = .14) for cardiovascular death. The results were similar for total HF hospitalizations (without urgent HF visits) and cardiovascular death and in all subgroups, including those defined by EF.In the DELIVER trial, dapagliflozin reduced the rate of total HF events (first and subsequent HF hospitalizations and urgent HF visits) and cardiovascular death regardless of patient characteristics, including EF.ClinicalTrials.gov Identifier: NCT03619213}",
  issn = {2380-6583},
  doi = {10.1001/jamacardio.2023.0711},
  url = {https://doi.org/10.1001/jamacardio.2023.0711},
  eprint = {https://jamanetwork.com/journals/jamacardiology/articlepdf/2804311/jamacardiology\_jhund\_2023\_oi\_230016\_1686672869.34214.pdf}
}


@article{Brian-AOC,
  author = {Brian Lee Claggett  and Zachary R. McCaw  and Lu Tian  and John J. V. McMurray  and Pardeep S. Jhund  and Hajime Uno  and Marc A. Pfeffer  and Scott D. Solomon  and Lee-Jen Wei },
  title = {Quantifying Treatment Effects in Trials with Multiple Event-Time Outcomes},
  journal = {NEJM Evidence},
  volume = {1},
  number = {10},
  pages = {EVIDoa2200047},
  year = {2022},
  abstract = {Many formerly deadly conditions with short life expectancies have been transformed into chronic conditions characterized by multiple nonfatal clinical events, which has led to concerns about the value of conventional time-to-first-event analyses as an appropriate way to examine disease course and assess treatment efficacy. The authors describe a simple, and clinically interpretable, statistical approach to this problem that is a straightforward extension of the mean survival time.},
  doi = {10.1056/EVIDoa2200047},
  url = {https://evidence.nejm.org/doi/abs/10.1056/EVIDoa2200047},
  eprint = {https://evidence.nejm.org/doi/pdf/10.1056/EVIDoa2200047}
}

@article{Joint-Model,
  author = {Chesnaye, Nicholas C and Tripepi, Giovanni and Dekker, Friedo W and Zoccali, Carmine and Zwinderman, Aeilko H and Jager, Kitty J},
  title = "{An introduction to joint models—applications in nephrology}",
  journal = {Clinical Kidney Journal},
  volume = {13},
  number = {2},
  pages = {143-149},
  year = {2020},
  month = {04},
  abstract = "{In nephrology, a great deal of information is measured repeatedly in patients over time, often alongside data on events of clinical interest. In this introductory article we discuss how these two types of data can be simultaneously analysed using the joint model (JM) framework, illustrated by clinical examples from nephrology. As classical survival analysis and linear mixed models form the two main components of the JM framework, we will also briefly revisit these techniques.}",
  issn = {2048-8505},
  doi = {10.1093/ckj/sfaa024},
  url = {https://doi.org/10.1093/ckj/sfaa024},
  eprint = {https://academic.oup.com/ckj/article-pdf/13/2/143/33028090/sfaa024.pdf}
}

@article{Kosiborod-Design,
  author = {Mikhail N. Kosiborod and Steen Z. Abildstrøm and Barry A. Borlaug and Javed Butler and Louise Christensen and Melanie Davies and Kees G. Hovingh and Dalane W. Kitzman and Marie L. Lindegaard and Daniél Vega Møller and Sanjiv J. Shah and Marianne Bach Treppendahl and Subodh Verma and Mark C. Petrie},
  title = {Design and Baseline Characteristics of STEP-HFpEF Program Evaluating Semaglutide in Patients With Obesity HFpEF Phenotype},
  journal = {JACC: Heart Failure},
  volume = {11},
  number = {8, Part 1},
  pages = {1000-1010},
  year = {2023},
  keywords = {6-minute walking distance, health status, HFpEF, Kansas City Cardiomyopathy Questionnaire, obesity, semaglutide, weight loss},
  abstract = {Background
The majority of patients with heart failure with preserved ejection fraction (HFpEF) have the obesity phenotype, but no therapies specifically targeting obesity in HFpEF exist.
Objectives
The aim of this study was to describe the design and baseline characteristics of 2 trials of semaglutide, a glucagon-like peptide-1 receptor agonist, in patients with the obesity HFpEF phenotype: STEP-HFpEF (Semaglutide Treatment Effect in People with obesity and HFpEF; NCT04788511) and STEP-HFpEF DM (Semaglutide Treatment Effect in People with obesity and HFpEF and type 2 diabetes; NCT04916470).
Methods
Both STEP-HFpEF and STEP-HFpEF DM are international multicenter, double-blind, placebo-controlled trials that randomized adults with HFpEF and a body mass index ≥30 kg/m2 to once-weekly semaglutide at a dose of 2.4 mg or placebo. Participants were eligible if they had a left ventricular ejection fraction (LVEF) ≥45%; NYHA functional class II to IV; a Kansas City Cardiomyopathy Questionnaire (KCCQ)–Clinical Summary Score (CSS) <90 points; and ≥1 of the following: elevated filling pressures, elevated natriuretic peptides plus structural echocardiographic abnormalities, recent heart failure hospitalization plus ongoing diuretic use, and/or structural abnormalities. The dual primary endpoints are the 52-week change in the KCCQ-CSS and body weight.
Results
In STEP-HFpEF and STEP-HFpEF DM (N = 529 and N = 617, respectively), nearly half were women, and most had severe obesity (median body mass index of 37 kg/m2) with typical features of HFpEF (median LVEF of 57%, frequent comorbidities, and elevated natriuretic peptides). Most participants received diuretic agents and renin-angiotensin blockers at baseline, and approximately one-third were on mineralocorticoid receptor antagonists. Sodium-glucose cotransporter-2 inhibitor use was rare in STEP-HFpEF but not in STEP HFpEF DM (32%). Patients in both trials had marked symptomatic and functional impairments (KCCQ-CSS ∼59 points, 6-minute walking distance ∼300 m).
Conclusions
In total, STEP-HFpEF program randomized 1,146 participants with the obesity phenotype of HFpEF and will determine whether semaglutide improves symptoms, physical limitations, and exercise function in addition to weight loss in this vulnerable group.},
  issn = {2213-1779},
  doi = {https://doi.org/10.1016/j.jchf.2023.05.010},
  url = {https://www.sciencedirect.com/science/article/pii/S2213177923002457}
}


@article{Ajufo-Win-Statistics,
  author = {Ezimamaka Ajufo and Aditi Nayak and Mandeep R. Mehra},
  title = {Fallacies of Using the Win Ratio in Cardiovascular Trials: Challenges and Solutions},
  journal = {JACC: Basic to Translational Science},
  volume = {8},
  number = {6},
  pages = {720-727},
  year = {2023},
  keywords = {cardiovascular trials, clinical significance, hierarchal endpoints, statistics, win odds, win ratio},
abstract = {Summary
The win ratio was introduced into cardiovascular trials as a potentially better way of analyzing composite endpoints to account for the hierarchy of clinical significance of their components and to facilitate the inclusion of recurrent events. The basic concept of the win ratio is to define a hierarchy of clinical importance within the components of the composite outcome, form all possible pairs by comparing every subject in the treatment group with every subject in the control group, and then evaluate each pair for the occurrence of the components of the composite outcome in descending order of importance, starting at the most important and progressing down the hierarchy if the outcome does not result in a win in either pair until pairs are tied for the outcome after exhaustion of all components. Although the win ratio offers a novel method of depiction of outcomes in clinical trials, its advantages may be counterbalanced by several fallacies (such as ignoring ties and weighting each hierarchal component equally) and challenges in appropriate clinical interpretation (establishing clinical meaningfulness of the observed effect size). From this perspective, we discuss these and other fallacies and provide a suggested framework to overcome such limitations to enhance utility of this statistical method across the clinical trial enterprise.},
  issn = {2452-302X},
  doi = {https://doi.org/10.1016/j.jacbts.2023.05.004},
  url = {https://www.sciencedirect.com/science/article/pii/S2452302X23002024}
}

@article{Maarten-Questions-AI,
  author = {van Smeden, Maarten and Heinze, Georg and Van Calster, Ben and Asselbergs, Folkert W and Vardas, Panos E and Bruining, Nico and de Jaegere, Peter and Moore, Jason H and Denaxas, Spiros and Boulesteix, Anne Laure and Moons, Karel G M},
  title = {Critical appraisal of artificial intelligence-based prediction models for cardiovascular disease},
  journal = {European Heart Journal},
  volume = {43},
  number = {31},
  pages = {2921-2930},
  year = {2022},
  month = {05},
  abstract = "{The medical field has seen a rapid increase in the development of artificial intelligence (AI)-based prediction models. With the introduction of such AI-based prediction model tools and software in cardiovascular patient care, the cardiovascular researcher and healthcare professional are challenged to understand the opportunities as well as the limitations of the AI-based predictions. In this article, we present 12 critical questions for cardiovascular health professionals to ask when confronted with an AI-based prediction model. We aim to support medical professionals to distinguish the AI-based prediction models that can add value to patient care from the AI that does not.}",
  issn = {0195-668X},
  doi = {10.1093/eurheartj/ehac238},
  url = {https://doi.org/10.1093/eurheartj/ehac238},
  eprint = {https://academic.oup.com/eurheartj/article-pdf/43/31/2921/45333809/ehac238.pdf}
}

@article{Hernandez,
  title = {Machine Learning Prediction Models for In-Hospital Mortality After Transcatheter Aortic Valve Replacement},
  author = {Dagmar F. Hernandez-Suarez and Yeunjung Kim and Pedro Villablanca and Tanush Gupta and Jose Wiley and Brenda G. Nieves-Rodriguez and Jovaniel Rodriguez-Maldonado and Roberto {Feliu Maldonado} and Istoni {da Luz Sant'Ana} and Cristina Sanina and Pedro Cox-Alomar and Harish Ramakrishna and Angel Lopez-Candales and William W. O’Neill and Duane S. Pinto and Azeem Latib and Abiel Roche-Lima},
  journal = {JACC: Cardiovascular Interventions},
  volume = {12},
  number = {14},
  pages = {1328-1338},
  year = {2019},
  keywords = {machine learning, mortality, transcatheter aortic valve replacement},
  abstract = {Objectives
This study sought to develop and compare an array of machine learning methods to predict in-hospital mortality after transcatheter aortic valve replacement (TAVR) in the United States.
Background
Existing risk prediction tools for in-hospital complications in patients undergoing TAVR have been designed using statistical modeling approaches and have certain limitations.
Methods
Patient data were obtained from the National Inpatient Sample database from 2012 to 2015. The data were randomly divided into a development cohort (n = 7,615) and a validation cohort (n = 3,268). Logistic regression, artificial neural network, naive Bayes, and random forest machine learning algorithms were applied to obtain in-hospital mortality prediction models.
Results
A total of 10,883 TAVRs were analyzed in our study. The overall in-hospital mortality was 3.6%. Overall, prediction models’ performance measured by area under the curve were good (>0.80). The best model was obtained by logistic regression (area under the curve: 0.92; 95% confidence interval: 0.89 to 0.95). Most obtained models plateaued after introducing 10 variables. Acute kidney injury was the main predictor of in-hospital mortality ranked with the highest mean importance in all the models. The National Inpatient Sample TAVR score showed the best discrimination among available TAVR prediction scores.
Conclusions
Machine learning methods can generate robust models to predict in-hospital mortality for TAVR. The National Inpatient Sample TAVR score should be considered for prognosis and shared decision making in TAVR patients.},
  issn = {1936-8798},
  doi = {https://doi.org/10.1016/j.jcin.2019.06.013},
  url = {https://www.sciencedirect.com/science/article/pii/S1936879819313123}
}

@article{Collins,
  author = {Collins, Gary S. and Reitsma, Johannes B. and Altman, Douglas G. and Moons, Karel GM},
  title = "{Transparent reporting of a multivariable prediction model for individual prognosis or diagnosis (TRIPOD): the TRIPOD Statement}",
  journal = {BMC Medicine},
  volume = {13},
  number = {1},
  pages = {1},
  year = {2015},
  month = {Jan},
  day = {06},
  abstract={Prediction models are developed to aid health care providers in estimating the probability or risk that a specific disease or condition is present (diagnostic models) or that a specific event will occur in the future (prognostic models), to inform their decision making. However, the overwhelming evidence shows that the quality of reporting of prediction model studies is poor. Only with full and clear reporting of information on all aspects of a prediction model can risk of bias and potential usefulness of prediction models be adequately assessed. The Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD) Initiative developed a set of recommendations for the reporting of studies developing, validating, or updating a prediction model, whether for diagnostic or prognostic purposes. This article describes how the TRIPOD Statement was developed. An extensive list of items based on a review of the literature was created, which was reduced after a Web-based survey and revised during a 3-day meeting in June 2011 with methodologists, health care professionals, and journal editors. The list was refined during several meetings of the steering group and in e-mail discussions with the wider group of TRIPOD contributors. The resulting TRIPOD Statement is a checklist of 22 items, deemed essential for transparent reporting of a prediction model study. The TRIPOD Statement aims to improve the transparency of the reporting of a prediction model study regardless of the study methods used. The TRIPOD Statement is best used in conjunction with the TRIPOD explanation and elaboration document. To aid the editorial process and readers of prediction model studies, it is recommended that authors include a completed checklist in their submission (also available at www.tripod-statement.org).},
  issn={1741-7015},
  doi={10.1186/s12916-014-0241-z},
  url={https://doi.org/10.1186/s12916-014-0241-z}
}

@article{Wynantsm1328,
	author = {Wynants, Laure and Van Calster, Ben and Collins, Gary S and Riley, Richard D and Heinze, Georg and Schuit, Ewoud and Albu, Elena and Arshi, Banafsheh and Bellou, Vanesa and Bonten, Marc M J and Dahly, Darren L and Damen, Johanna A and Debray, Thomas P A and de Jong, Valentijn M T and De Vos, Maarten and Dhiman, Paula and Ensor, Joie and Gao, Shan and Haller, Maria C and Harhay, Michael O and Henckaerts, Liesbet and Heus, Pauline and Hoogland, Jeroen and Hudda, Mohammed and Jenniskens, Kevin and Kammer, Michael and Kreuzberger, Nina and Lohmann, Anna and Levis, Brooke and Luijken, Kim and Ma, Jie and Martin, Glen P and McLernon, David J and Navarro, Constanza L Andaur and Reitsma, Johannes B and Sergeant, Jamie C and Shi, Chunhu and Skoetz, Nicole and Smits, Luc J M and Snell, Kym I E and Sperrin, Matthew and Spijker, Ren{\'e} and Steyerberg, Ewout W and Takada, Toshihiko and Tzoulaki, Ioanna and van Kuijk, Sander M J and van Bussel, Bas C T and van der Horst, Iwan C C and Reeve, Kelly and van Royen, Florien S and Verbakel, Jan Y and Wallisch, Christine and Wilkinson, Jack and Wolff, Robert and Hooft, Lotty and Moons, Karel G M and van Smeden, Maarten},
	title = {Prediction models for diagnosis and prognosis of covid-19: systematic review and critical appraisal},
	journal = {BMJ},
	volume = {369},
	elocation-id = {m1328},
	year = {2020},
	publisher = {BMJ Publishing Group Ltd},
	abstract = {Objective To review and appraise the validity and usefulness of published and preprint reports of prediction models for prognosis of patients with covid-19, and for detecting people in the general population at increased risk of covid-19 infection or being admitted to hospital or dying with the disease.Design Living systematic review and critical appraisal by the covid-PRECISE (Precise Risk Estimation to optimise covid-19 Care for Infected or Suspected patients in diverse sEttings) group.Data sources PubMed and Embase through Ovid, up to 17 February 2021, supplemented with arXiv, medRxiv, and bioRxiv up to 5 May 2020.Study selection Studies that developed or validated a multivariable covid-19 related prediction model.Data extraction At least two authors independently extracted data using the CHARMS (critical appraisal and data extraction for systematic reviews of prediction modelling studies) checklist; risk of bias was assessed using PROBAST (prediction model risk of bias assessment tool).Results 126 978 titles were screened, and 412 studies describing 731 new prediction models or validations were included. Of these 731, 125 were diagnostic models (including 75 based on medical imaging) and the remaining 606 were prognostic models for either identifying those at risk of covid-19 in the general population (13 models) or predicting diverse outcomes in those individuals with confirmed covid-19 (593 models). Owing to the widespread availability of diagnostic testing capacity after the summer of 2020, this living review has now focused on the prognostic models. Of these, 29 had low risk of bias, 32 had unclear risk of bias, and 545 had high risk of bias. The most common causes for high risk of bias were inadequate sample sizes (n=408, 67\%) and inappropriate or incomplete evaluation of model performance (n=338, 56\%). 381 models were newly developed, and 225 were external validations of existing models. The reported C indexes varied between 0.77 and 0.93 in development studies with low risk of bias, and between 0.56 and 0.78 in external validations with low risk of bias. The Qcovid models, the PRIEST score, Carr{\textquoteright}s model, the ISARIC4C Deterioration model, and the Xie model showed adequate predictive performance in studies at low risk of bias. Details on all reviewed models are publicly available at https://www.covprecise.org/.Conclusion Prediction models for covid-19 entered the academic literature to support medical decision making at unprecedented speed and in large numbers. Most published prediction model studies were poorly reported and at high risk of bias such that their reported predictive performances are probably optimistic. Models with low risk of bias should be validated before clinical implementation, preferably through collaborative efforts to also allow an investigation of the heterogeneity in their performance across various populations and settings. Methodological guidance, as provided in this paper, should be followed because unreliable predictions could cause more harm than benefit in guiding clinical decisions. Finally, prediction modellers should adhere to the TRIPOD (transparent reporting of a multivariable prediction model for individual prognosis or diagnosis) reporting guideline.Systematic review registration Protocol https://osf.io/ehc47/, registration https://osf.io/wy245.Readers{\textquoteright} note This article is the final version of a living systematic review that has been updated over the past two years to reflect emerging evidence. This version is update 4 of the original article published on 7 April 2020 (BMJ 2020;369:m1328). Previous updates can be found as data supplements (https://www.bmj.com/content/369/bmj.m1328/related$\#$datasupp). When citing this paper please consider adding the update number and date of access for clarity.The study protocol is available online at https://osf.io/ehc47/. Detailed extracted data on all included studies are available on https://www.covprecise.org/.},
	doi = {10.1136/bmj.m1328},
	url = {https://www.bmj.com/content/369/bmj.m1328},
	eprint = {https://www.bmj.com/content/369/bmj.m1328.full.pdf}
}

@article{ANDAURNAVARRO202399,
  author = {Constanza L. {Andaur Navarro} and Johanna A.A. Damen and Toshihiko Takada and Steven W.J. Nijman and Paula Dhiman and Jie Ma and Gary S. Collins and Ram Bajpai and Richard D. Riley and Karel G.M. Moons and Lotty Hooft},
keywords = {Diagnosis, Prognosis, Development, Validation, Misinterpretation, Overinterpretation, Overextrapolation, Spin},
  title = {Systematic review finds “spin” practices and poor reporting standards in studies on machine learning-based prediction models},
  journal = {Journal of Clinical Epidemiology},
  volume = {158},
  pages = {99-110},
  year = {2023},
  abstract = {Objectives
We evaluated the presence and frequency of spin practices and poor reporting standards in studies that developed and/or validated clinical prediction models using supervised machine learning techniques.
Study Design and Setting
We systematically searched PubMed from 01/2018 to 12/2019 to identify diagnostic and prognostic prediction model studies using supervised machine learning. No restrictions were placed on data source, outcome, or clinical specialty.
Results
We included 152 studies: 38% reported diagnostic models and 62% prognostic models. When reported, discrimination was described without precision estimates in 53/71 abstracts (74.6% [95% CI 63.4–83.3]) and 53/81 main texts (65.4% [95% CI 54.6–74.9]). Of the 21 abstracts that recommended the model to be used in daily practice, 20 (95.2% [95% CI 77.3–99.8]) lacked any external validation of the developed models. Likewise, 74/133 (55.6% [95% CI 47.2–63.8]) studies made recommendations for clinical use in their main text without any external validation. Reporting guidelines were cited in 13/152 (8.6% [95% CI 5.1–14.1]) studies.
Conclusion
Spin practices and poor reporting standards are also present in studies on prediction models using machine learning techniques. A tailored framework for the identification of spin will enhance the sound reporting of prediction model studies.},
  issn = {0895-4356},
  doi = {https://doi.org/10.1016/j.jclinepi.2023.03.024},
  url = {https://www.sciencedirect.com/science/article/pii/S0895435623000756},
}

@article{Dhiman2022,
  author={Dhiman, Paula and Ma, Jie and Andaur Navarro, Constanza L. and Speich, Benjamin and Bullock, Garrett and Damen, Johanna A. A. and Hooft, Lotty and Kirtley, Shona and Riley, Richard D. and Van Calster, Ben and Moons, Karel G. M. and Collins, Gary S.},
  title={Risk of bias of prognostic models developed using machine learning: a systematic review in oncology},
  journal={Diagnostic and Prognostic Research},
  year={2022},
  month={Jul},
  day={07},
  volume={6},
  number={1},
  pages={13},
  abstract={Prognostic models are used widely in the oncology domain to guide medical decision-making. Little is known about the risk of bias of prognostic models developed using machine learning and the barriers to their clinical uptake in the oncology domain.},
  issn={2397-7523},
  doi={10.1186/s41512-022-00126-w},
  url={https://doi.org/10.1186/s41512-022-00126-w}
}

@inproceedings{Sculley,
 author = {Sculley, D. and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Crespo, Jean-Fran\c{c}ois and Dennison, Dan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Hidden Technical Debt in Machine Learning Systems},
 url = {https://proceedings.neurips.cc/paper_files/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf},
 volume = {28},
 year = {2015}
}

@article{Royen2200250,
	author = {Florien S. van Royen and Karel G.M. Moons and Geert-Jan Geersing and Maarten van Smeden},
	title = {Developing, validating, updating and judging the impact of prognostic models for respiratory diseases},
	elocation-id = {2200250},
	year = {2022},
	doi = {10.1183/13993003.00250-2022},
	publisher = {European Respiratory Society},
	issn = {0903-1936},
	url = {https://erj.ersjournals.com/content/early/2022/05/26/13993003.00250-2022},
	eprint = {https://erj.ersjournals.com/content/early/2022/05/26/13993003.00250-2022.full.pdf},
	journal = {European Respiratory Journal}
}

